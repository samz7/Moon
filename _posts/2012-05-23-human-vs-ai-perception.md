---
layout: post
title: "AI perception vs Human Perception"
date: 2020-04-02
categories: posts
excerpt: "Can we ever make an AI understand what we are perceiving?"
tags: [sample post, readability, test, image, feature]
feature: https://images.unsplash.com/photo-1483519173755-be893fab1f46?ixlib=rb-1.2.1&w=1000&q=80
comments: true
---

I was recently listening to Lex Fridman's <a href="https://www.youtube.com/playlist?list=PLrAXtmErZgOeciFP3CBCIEElOJeitOr41" target="_blank">AI podcast.</a> Lex asked Elon Musk what the harder problem in the field of Self Driving Car is, The Perception or The Control. So making AI understand what it is experiencing in the world or making calculated judgements based on those perceptions?

Elon in typical Elon Musk fashion said 
> "The hardest thing is having accurate representation of real world objects in vector space" 

That got me thinking, can we ever accurately represent our real world with vectors and matrices? In other words can we reliably transmit all there is about our world and condense it into a bunch of structured numbers essentially.
Well recent developments in Computer Vision will make you say of course we can. Neural Networks can reliably predict what it is seeing in an image, <a href="https://news.stanford.edu/2017/11/15/algorithm-outperforms-radiologists-diagnosing-pneumonia/" target="_blank">sometimes even better than humans.</a> So that means the perception problem must be solved right? We have figured out a way to condense the real world information into numbers? Not Quite. Yes, computer scientists and researchers have figured out ways to represent a lot of the real world information into numbers, lets say we are looking at a 3d matrix that represents an apple and if we understand everything about that matrix we will have a pretty good structural idea about what an apple is. But looking at the apple itself adds more knowledge, or does it?  

## The Knowledge Argument

Time for some philosophy. There is a great thought experiment called the <a href="https://www.youtube.com/watch?v=mGYmiQkah4o" target="_blank">Mary's Room thought experiment</a> that kind of asks the questions whether or not conscious experience involves non-physical properties. It suggests that even if someone has complete theoretical knowledge about a certain thing, more knowledge can be acquired by experiencing that thing. Mary knows everything there is to know about colors. She knows every single property of color everything from the different pigments to the wave forms that it creates to even what kind of neurons light up when humans look at color. But, and here is the catch, Mary is color blind. She never in her entire life perceived color but knows everything about it. So now the question is will she learn anything new about color if somehow she could see color again? Will that experience hold any new information that was not captured by the theories.

In our world AI is Mary. We have condensed "everything" about percieving a real world thing into a matrix form for the AI to **understand.** But without experiencing the thing can it ever really understand? Lets forget about the philosophical aspect for a second. We percieve the world we live in, on the other hand Neural networks are just mathmatical functions living inside of computer circuits. In order to truly understand what it is to percieve something in reality AI needs to understand the higher level concepts of the objects that its perceiving, how the different objects interact, what their relationships are. This is what Yoshua Bengio a renowned AI researcher calls Higher Level Cognition.

Current neural networks are great at recognizing patterns in the matrices, but really doesn't know what those patterns **mean.** There is a lot to uncover in the world of AI. This is one reason to become excited about the future.